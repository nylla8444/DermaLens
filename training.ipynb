{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3050d48",
   "metadata": {},
   "source": [
    "# DermaLens - Dog Skin Lesion Classification Training\n",
    "## CCS 248 Course Project\n",
    "\n",
    "This notebook contains the complete training pipeline for a ResNet50 deep neural network trained from scratch on dog skin lesion images.\n",
    "\n",
    "**Dataset**: 5,530 images across 6 disease classes  \n",
    "**Model**: ResNet50 (25.5M parameters, from scratch)  \n",
    "**Optimizer**: AdamW (lr=0.01, weight_decay=0.0001)  \n",
    "**Training**: 143 epochs (best model at epoch 122)  \n",
    "**Final Test Accuracy**: 86.61%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab77ab24",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import all necessary libraries for deep learning, data processing, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e623873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, Optional, List\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "# Machine learning utilities\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuration\n",
    "import yaml\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6512ca",
   "metadata": {},
   "source": [
    "## 2. Load Configuration and Prepare Environment\n",
    "\n",
    "Load training hyperparameters from config file and set up directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd2b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration from YAML file\n",
    "with open('configs/config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Display configuration\n",
    "print(\"=\" * 50)\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Model: {config['model']['architecture']}\")\n",
    "print(f\"Pretrained: {config['model']['pretrained']}\")  # Should be False\n",
    "print(f\"Num Classes: {config['model']['num_classes']}\")\n",
    "print(f\"Dropout Rate: {config['model']['dropout_rate']}\")\n",
    "print()\n",
    "print(f\"Learning Rate: {config['training']['learning_rate']}\")\n",
    "print(f\"Weight Decay: {config['training']['weight_decay']}\")\n",
    "print(f\"Batch Size: {config['training']['batch_size']}\")\n",
    "print(f\"Num Epochs: {config['training']['num_epochs']}\")\n",
    "print(f\"Early Stopping Patience: {config['training']['early_stopping_patience']}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "\n",
    "# Create directories\n",
    "Path(config['training']['model_save_dir']).mkdir(parents=True, exist_ok=True)\n",
    "Path(config['training']['log_dir']).mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Checkpoint dir: {config['training']['model_save_dir']}\")\n",
    "print(f\"Log dir: {config['training']['log_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73be5b46",
   "metadata": {},
   "source": [
    "## 3. Define Custom Dataset Class\n",
    "\n",
    "Create PyTorch Dataset for loading and preprocessing dog skin lesion images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edd2eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogSkinLesionDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for dog skin lesion images\"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir: str, split: str, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir: Root directory containing dataset\n",
    "            split: 'train', 'valid', or 'test'\n",
    "            transform: Optional transform to be applied on images\n",
    "        \"\"\"\n",
    "        self.root_dir = Path(root_dir) / split\n",
    "        self.transform = transform\n",
    "        self.classes = sorted([d.name for d in self.root_dir.iterdir() if d.is_dir()])\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        \n",
    "        # Load all image paths and labels\n",
    "        self.samples = []\n",
    "        for class_name in self.classes:\n",
    "            class_dir = self.root_dir / class_name\n",
    "            for img_path in class_dir.glob('*'):\n",
    "                if img_path.suffix.lower() in ['.jpg', '.jpeg', '.png']:\n",
    "                    self.samples.append((str(img_path), self.class_to_idx[class_name]))\n",
    "        \n",
    "        print(f\"{split.upper()} SET: {len(self.samples)} images across {len(self.classes)} classes\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Test dataset loading\n",
    "print(\"\\nTesting dataset loading...\")\n",
    "test_dataset = DogSkinLesionDataset(\n",
    "    root_dir=config['dataset']['dataset_path'],\n",
    "    split='train',\n",
    "    transform=None\n",
    ")\n",
    "print(f\"Classes: {test_dataset.classes}\")\n",
    "print(f\"Sample image shape: {np.array(test_dataset[0][0]).shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8596424e",
   "metadata": {},
   "source": [
    "## 4. Define Data Augmentation and Create DataLoaders\n",
    "\n",
    "Set up data augmentation for training and create DataLoaders for all splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f75e643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms for training (with augmentation)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(\n",
    "        config['dataset']['image_size'],\n",
    "        scale=(config['augmentation']['scale_min'], config['augmentation']['scale_max']),\n",
    "        ratio=(config['augmentation']['aspect_ratio_min'], config['augmentation']['aspect_ratio_max'])\n",
    "    ),\n",
    "    transforms.RandomHorizontalFlip() if config['augmentation']['random_flip'] else transforms.Lambda(lambda x: x),\n",
    "    transforms.RandomRotation(config['augmentation']['random_rotation']),\n",
    "    transforms.ColorJitter(\n",
    "        brightness=config['augmentation']['brightness'],\n",
    "        contrast=config['augmentation']['contrast'],\n",
    "        saturation=config['augmentation']['saturation'],\n",
    "        hue=config['augmentation']['hue']\n",
    "    ) if config['augmentation']['color_jitter'] else transforms.Lambda(lambda x: x),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Define transforms for validation/test (no augmentation)\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(config['dataset']['image_size']),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = DogSkinLesionDataset(\n",
    "    root_dir=config['dataset']['dataset_path'],\n",
    "    split=config['dataset']['train_split'],\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "valid_dataset = DogSkinLesionDataset(\n",
    "    root_dir=config['dataset']['dataset_path'],\n",
    "    split=config['dataset']['valid_split'],\n",
    "    transform=val_transform\n",
    ")\n",
    "\n",
    "test_dataset = DogSkinLesionDataset(\n",
    "    root_dir=config['dataset']['dataset_path'],\n",
    "    split=config['dataset']['test_split'],\n",
    "    transform=val_transform\n",
    ")\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = config['training']['batch_size']\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Valid batches: {len(valid_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76352ded",
   "metadata": {},
   "source": [
    "## 5. Define ResNet50 Model Architecture\n",
    "\n",
    "Build ResNet50 from scratch with custom classification head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c8e8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DermaLensModel(nn.Module):\n",
    "    \"\"\"ResNet50-based model for dog skin lesion classification\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=6, dropout_rate=0.3, pretrained=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load ResNet50 backbone (from scratch or pretrained)\n",
    "        self.backbone = models.resnet50(weights=None if not pretrained else models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        # Get number of features from backbone\n",
    "        num_features = self.backbone.fc.in_features\n",
    "        \n",
    "        # Replace final layer with custom classification head\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "    \n",
    "    def count_parameters(self):\n",
    "        \"\"\"Count total and trainable parameters\"\"\"\n",
    "        total = sum(p.numel() for p in self.parameters())\n",
    "        trainable = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        return total, trainable\n",
    "\n",
    "# Create model\n",
    "model = DermaLensModel(\n",
    "    num_classes=config['model']['num_classes'],\n",
    "    dropout_rate=config['model']['dropout_rate'],\n",
    "    pretrained=config['model']['pretrained']  # Should be False\n",
    ").to(device)\n",
    "\n",
    "# Display model info\n",
    "total_params, trainable_params = model.count_parameters()\n",
    "print(\"=\" * 50)\n",
    "print(\"MODEL ARCHITECTURE\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Model: ResNet50\")\n",
    "print(f\"Pretrained: {config['model']['pretrained']}\")\n",
    "print(f\"Total Parameters: {total_params:,}\")\n",
    "print(f\"Trainable Parameters: {trainable_params:,}\")\n",
    "print(f\"Model size: ~{total_params * 4 / 1024 / 1024:.1f} MB\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d088b752",
   "metadata": {},
   "source": [
    "## 6. Configure Optimizer, Loss Function, and Scheduler\n",
    "\n",
    "Set up AdamW optimizer with weight decay, CrossEntropy loss, and ReduceLROnPlateau scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375fa804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer: AdamW (Adam with decoupled weight decay)\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config['training']['learning_rate'],\n",
    "    weight_decay=config['training']['weight_decay']\n",
    ")\n",
    "\n",
    "# Learning rate scheduler: ReduceLROnPlateau\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='max',  # Maximize validation accuracy\n",
    "    factor=0.5,  # Reduce LR by 50%\n",
    "    patience=5,  # Wait 5 epochs before reducing\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"TRAINING SETUP\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Optimizer: AdamW\")\n",
    "print(f\"Learning Rate: {config['training']['learning_rate']}\")\n",
    "print(f\"Weight Decay: {config['training']['weight_decay']}\")\n",
    "print(f\"Loss Function: CrossEntropyLoss\")\n",
    "print(f\"LR Scheduler: ReduceLROnPlateau (factor=0.5, patience=5)\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bafe8d7",
   "metadata": {},
   "source": [
    "## 7. Define Training and Validation Functions\n",
    "\n",
    "Implement training loop and validation evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd04daf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=\"Training\")\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    \"\"\"Validate model\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc=\"Validating\")\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "    epoch_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    return epoch_loss, epoch_acc, epoch_f1\n",
    "\n",
    "print(\"Training and validation functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af61eb6c",
   "metadata": {},
   "source": [
    "## 8. Train the Model\n",
    "\n",
    "Run complete training loop with early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a43cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'valid_loss': [],\n",
    "    'valid_acc': [],\n",
    "    'valid_f1': [],\n",
    "    'learning_rate': []\n",
    "}\n",
    "\n",
    "# Early stopping variables\n",
    "best_valid_acc = 0.0\n",
    "best_epoch = 0\n",
    "patience_counter = 0\n",
    "num_epochs = config['training']['num_epochs']\n",
    "early_stopping_patience = config['training']['early_stopping_patience']\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total Epochs: {num_epochs}\")\n",
    "print(f\"Early Stopping Patience: {early_stopping_patience}\")\n",
    "print(\"=\" * 50 + \"\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Validate\n",
    "    valid_loss, valid_acc, valid_f1 = validate(model, valid_loader, criterion, device)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(valid_acc)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['valid_loss'].append(valid_loss)\n",
    "    history['valid_acc'].append(valid_acc)\n",
    "    history['valid_f1'].append(valid_f1)\n",
    "    history['learning_rate'].append(current_lr)\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"\\nTrain Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Valid Loss: {valid_loss:.4f} | Valid Acc: {valid_acc:.4f} | Valid F1: {valid_f1:.4f}\")\n",
    "    print(f\"Learning Rate: {current_lr:.6f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        best_epoch = epoch + 1\n",
    "        patience_counter = 0\n",
    "        \n",
    "        # Save checkpoint\n",
    "        checkpoint_path = Path(config['training']['model_save_dir']) / 'best_model.pth'\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'valid_acc': valid_acc,\n",
    "            'valid_f1': valid_f1,\n",
    "            'config': config\n",
    "        }, checkpoint_path)\n",
    "        print(f\"✓ New best model saved! (Val Acc: {valid_acc:.4f})\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"No improvement for {patience_counter} epoch(s)\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= early_stopping_patience:\n",
    "        print(f\"\\n⚠ Early stopping triggered after {epoch+1} epochs\")\n",
    "        print(f\"Best validation accuracy: {best_valid_acc:.4f} at epoch {best_epoch}\")\n",
    "        break\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total Training Time: {training_time/3600:.2f} hours\")\n",
    "print(f\"Best Validation Accuracy: {best_valid_acc:.4f} at Epoch {best_epoch}\")\n",
    "print(f\"Final Model: {checkpoint_path}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3334b47",
   "metadata": {},
   "source": [
    "## 9. Save Training History\n",
    "\n",
    "Save training metrics to JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6546a965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training history\n",
    "history_path = Path(config['training']['log_dir']) / 'training_history.json'\n",
    "with open(history_path, 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "\n",
    "print(f\"Training history saved to: {history_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d675e7",
   "metadata": {},
   "source": [
    "## 10. Visualize Training Progress\n",
    "\n",
    "Plot training and validation loss/accuracy curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1658f40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot loss\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "axes[0].plot(history['valid_loss'], label='Valid Loss', marker='s')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Plot accuracy\n",
    "axes[1].plot(history['train_acc'], label='Train Accuracy', marker='o')\n",
    "axes[1].plot(history['valid_acc'], label='Valid Accuracy', marker='s')\n",
    "axes[1].axhline(y=best_valid_acc, color='r', linestyle='--', label=f'Best Val Acc: {best_valid_acc:.4f}')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Training and Validation Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plot_path = Path(config['training']['log_dir']) / 'training_history.png'\n",
    "plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "print(f\"Training plot saved to: {plot_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3f3d9d",
   "metadata": {},
   "source": [
    "## 11. Evaluate on Test Set\n",
    "\n",
    "Load best model and evaluate on test set for final performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35eaed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\nEvaluating on Test Set...\")\n",
    "test_loss, test_acc, test_f1 = validate(model, test_loader, criterion, device)\n",
    "\n",
    "# Get predictions for all splits\n",
    "def get_predictions(model, dataloader, device):\n",
    "    \"\"\"Get all predictions and labels\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Predicting\"):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    \n",
    "    return np.array(all_preds), np.array(all_labels)\n",
    "\n",
    "# Get predictions\n",
    "train_preds, train_labels = get_predictions(model, train_loader, device)\n",
    "valid_preds, valid_labels = get_predictions(model, valid_loader, device)\n",
    "test_preds, test_labels = get_predictions(model, test_loader, device)\n",
    "\n",
    "# Calculate metrics for all splits\n",
    "results = {\n",
    "    'train': {\n",
    "        'accuracy': accuracy_score(train_labels, train_preds),\n",
    "        'precision': precision_score(train_labels, train_preds, average='weighted'),\n",
    "        'recall': recall_score(train_labels, train_preds, average='weighted'),\n",
    "        'f1': f1_score(train_labels, train_preds, average='weighted')\n",
    "    },\n",
    "    'validation': {\n",
    "        'accuracy': accuracy_score(valid_labels, valid_preds),\n",
    "        'precision': precision_score(valid_labels, valid_preds, average='weighted'),\n",
    "        'recall': recall_score(valid_labels, valid_preds, average='weighted'),\n",
    "        'f1': f1_score(valid_labels, valid_preds, average='weighted')\n",
    "    },\n",
    "    'test': {\n",
    "        'accuracy': accuracy_score(test_labels, test_preds),\n",
    "        'precision': precision_score(test_labels, test_preds, average='weighted'),\n",
    "        'recall': recall_score(test_labels, test_preds, average='weighted'),\n",
    "        'f1': f1_score(test_labels, test_preds, average='weighted')\n",
    "    }\n",
    "}\n",
    "\n",
    "# Print results\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FINAL EVALUATION RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "for split, metrics in results.items():\n",
    "    print(f\"\\n{split.upper()} SET:\")\n",
    "    print(f\"  Accuracy:  {metrics['accuracy']:.4f}\")\n",
    "    print(f\"  Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"  Recall:    {metrics['recall']:.4f}\")\n",
    "    print(f\"  F1 Score:  {metrics['f1']:.4f}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Save results\n",
    "results_path = Path(config['training']['log_dir']) / 'evaluation_results.json'\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(f\"\\nResults saved to: {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735814d2",
   "metadata": {},
   "source": [
    "## 12. Generate Confusion Matrix\n",
    "\n",
    "Visualize per-class prediction performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9219af75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=config['dataset']['class_names'],\n",
    "            yticklabels=config['dataset']['class_names'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title(f'Confusion Matrix - Test Set\\nOverall Accuracy: {results[\"test\"][\"accuracy\"]:.4f}')\n",
    "plt.tight_layout()\n",
    "\n",
    "cm_path = Path(config['training']['log_dir']) / 'confusion_matrix.png'\n",
    "plt.savefig(cm_path, dpi=150, bbox_inches='tight')\n",
    "print(f\"Confusion matrix saved to: {cm_path}\")\n",
    "plt.show()\n",
    "\n",
    "# Per-class metrics\n",
    "print(\"\\nPER-CLASS PERFORMANCE (Test Set):\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Class':<20} {'Precision':<12} {'Recall':<12} {'F1 Score':<12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for i, class_name in enumerate(config['dataset']['class_names']):\n",
    "    # Get samples for this class\n",
    "    class_mask = test_labels == i\n",
    "    class_preds = test_preds[class_mask]\n",
    "    class_labels = test_labels[class_mask]\n",
    "    \n",
    "    if len(class_labels) > 0:\n",
    "        prec = precision_score(class_labels, class_preds, labels=[i], average='micro')\n",
    "        rec = recall_score(class_labels, class_preds, labels=[i], average='micro')\n",
    "        f1 = f1_score(class_labels, class_preds, labels=[i], average='micro')\n",
    "        print(f\"{class_name:<20} {prec:<12.4f} {rec:<12.4f} {f1:<12.4f}\")\n",
    "\n",
    "print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0362793f",
   "metadata": {},
   "source": [
    "## 13. Make Sample Predictions\n",
    "\n",
    "Test the trained model on sample images from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ff4c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of test images\n",
    "images, labels = next(iter(test_loader))\n",
    "images = images.to(device)\n",
    "\n",
    "# Make predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)\n",
    "    probabilities = torch.softmax(outputs, dim=1)\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "# Denormalize images for visualization\n",
    "mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "\n",
    "# Plot sample predictions\n",
    "num_samples = min(8, len(images))\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Denormalize image\n",
    "    img = images[i].cpu() * std + mean\n",
    "    img = torch.clamp(img, 0, 1)\n",
    "    img = img.permute(1, 2, 0).numpy()\n",
    "    \n",
    "    # Plot\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].axis('off')\n",
    "    \n",
    "    # Get prediction info\n",
    "    true_label = config['dataset']['class_names'][labels[i]]\n",
    "    pred_label = config['dataset']['class_names'][predictions[i]]\n",
    "    confidence = probabilities[i][predictions[i]].item()\n",
    "    \n",
    "    # Color based on correctness\n",
    "    color = 'green' if predictions[i] == labels[i] else 'red'\n",
    "    axes[i].set_title(f\"True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.2%}\", \n",
    "                     color=color, fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ Displayed {num_samples} sample predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d715e9",
   "metadata": {},
   "source": [
    "## 14. Training Summary\n",
    "\n",
    "Display comprehensive summary of the training process and final results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1247624",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\" \" * 20 + \"TRAINING SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n{'CONFIGURATION':-^70}\")\n",
    "print(f\"Model:                ResNet50 (from scratch)\")\n",
    "print(f\"Total Parameters:     {total_params:,}\")\n",
    "print(f\"Pretrained:           {config['model']['pretrained']}\")\n",
    "print(f\"Optimizer:            AdamW\")\n",
    "print(f\"Learning Rate:        {config['training']['learning_rate']}\")\n",
    "print(f\"Weight Decay:         {config['training']['weight_decay']}\")\n",
    "print(f\"Batch Size:           {config['training']['batch_size']}\")\n",
    "print(f\"Training Time:        {training_time/3600:.2f} hours\")\n",
    "print(f\"Epochs Completed:     {len(history['train_loss'])}/{num_epochs}\")\n",
    "print(f\"\\n{'DATASET':-^70}\")\n",
    "print(f\"Training Images:      {len(train_dataset):,}\")\n",
    "print(f\"Validation Images:    {len(valid_dataset):,}\")\n",
    "print(f\"Test Images:          {len(test_dataset):,}\")\n",
    "print(f\"Total Images:         {len(train_dataset) + len(valid_dataset) + len(test_dataset):,}\")\n",
    "print(f\"Number of Classes:    {config['model']['num_classes']}\")\n",
    "print(f\"\\n{'FINAL RESULTS':-^70}\")\n",
    "print(f\"Best Validation Acc:  {best_valid_acc:.4f} (Epoch {best_epoch})\")\n",
    "print(f\"Test Accuracy:        {results['test']['accuracy']:.4f}\")\n",
    "print(f\"Test Precision:       {results['test']['precision']:.4f}\")\n",
    "print(f\"Test Recall:          {results['test']['recall']:.4f}\")\n",
    "print(f\"Test F1 Score:        {results['test']['f1']:.4f}\")\n",
    "print(f\"\\n{'GENERALIZATION':-^70}\")\n",
    "print(f\"Train Accuracy:       {results['train']['accuracy']:.4f}\")\n",
    "print(f\"Validation Accuracy:  {results['validation']['accuracy']:.4f}\")\n",
    "print(f\"Test Accuracy:        {results['test']['accuracy']:.4f}\")\n",
    "gap = results['test']['accuracy'] - results['validation']['accuracy']\n",
    "print(f\"Test-Val Gap:         {gap:+.4f} {'(Excellent!)' if gap >= 0 else '(Overfitting)'}\")\n",
    "print(f\"\\n{'OUTPUT FILES':-^70}\")\n",
    "print(f\"Best Model:           {checkpoint_path}\")\n",
    "print(f\"Training History:     {history_path}\")\n",
    "print(f\"Evaluation Results:   {results_path}\")\n",
    "print(f\"Training Plot:        {plot_path}\")\n",
    "print(f\"Confusion Matrix:     {cm_path}\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n✓ TRAINING COMPLETE - Model ready for deployment!\")\n",
    "print(f\"✓ To use this model, load from: {checkpoint_path}\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
